# ğŸŒ¿ U-Net Seagrass â€” High-Resolution Drone Imagery Segmentation

This repository provides a **U-Netâ€“based segmentation pipeline** for eelgrass mapping using high-resolution drone imagery (Alaska / California / Washington / Oregon / British Columbia / ).  
It supports **RGB**, **index channels**, and **custom multi-channel inputs** (e.g., RGB + Index + GLCM), and includes tiling, training, evaluation, and metric computation.

---

## ğŸ“‚ Repository Structure

```text
unet-seagrass/
â”‚
â”œâ”€â”€ train/                          # Training scripts
â”‚   â”œâ”€â”€ dataset/                    # Custom eelgrass dataset loader
â”‚   â”œâ”€â”€ transforms/                 # Data augmentation
â”‚   â”œâ”€â”€ work_dirs/                  # Logs, checkpoints, configs
â”‚   â””â”€â”€ train_unet.py               # Main U-Net training script
â”‚
â”œâ”€â”€ eval/                           # Evaluation + metrics
â”‚   â”œâ”€â”€ eval_unet.py
â”‚   â””â”€â”€ metrics/                    # IoU, Dice, F-score, boundary IoU
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ tiling/                     # Ortho/index 512Ã—512 tile generator
â”‚   â”œâ”€â”€ image_utils.py
â”‚   â””â”€â”€ augment.py
â”‚
â”œâ”€â”€ models/                         # U-Net architectures (SMP, custom UNet)
â”‚   â”œâ”€â”€ unet_smp.py
â”‚   â””â”€â”€ unet_custom.py
â”‚
â”œâ”€â”€ splits/                         # train/valid/test .txt file lists
â”œâ”€â”€ pretrained/                     # (Optional) pre-trained backbone weights
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Installation

Tested on:

- Python 3.8â€“3.10  
- PyTorch 1.12â€“2.2  
- CUDA 11.8 / 12.x  

Install environment:

```bash
conda create -n unet python=3.10 -y
conda activate unet
pip install -r requirements.txt
```

(Recommended) Install segmentation-models-pytorch:

```bash
pip install segmentation-models-pytorch
```

---

## ğŸ“ Dataset Format

Eelgrass tiles follow the 512Ã—512 PNG structure:

```text
data/
â”œâ”€â”€ BC/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ image/
â”‚   â”‚   â””â”€â”€ mask/
â”‚   â”œâ”€â”€ valid/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ OR/
â”œâ”€â”€ WA/
â””â”€â”€ AK/
```

Tile naming convention:

```
<site>_<region>_<year>_rowXX_colYY.png
```

Example:

```
BH_WA_19_row10_col50.png
```

Dataset list files (`train.txt`, `valid.txt`, `test.txt`) follow format:

```
BH_WA_19_row10_col50
BH_WA_19_row12_col33
...
```

(no extension)

---

## ğŸš€ Training

Basic U-Net (ResNet34 encoder):

```bash
python train/train_unet.py \
    --data-root /path/to/data \
    --split-root ./splits \
    --output ./train/work_dirs/unet_run1 \
    --encoder resnet34 \
    --epochs 40 \
    --batch-size 8
```

Multi-channel training (RGB + index):

```bash
python train/train_unet.py \
    --input-channels 4 \
    --modalities rgb index \
    --data-root /path/to/data \
    --output ./train/work_dirs/unet_4ch
```

Training outputs:

```
train/work_dirs/
    â”œâ”€â”€ checkpoints/
    â”œâ”€â”€ logs/
    â””â”€â”€ config.json
```

---

## ğŸ§ª Evaluation

Run evaluation on a trained checkpoint:

```bash
python eval/eval_unet.py \
    --data-root /path/to/data \
    --split ./splits/test.txt \
    --checkpoint ./train/work_dirs/unet_run1/best_model.pth \
    --output ./eval/results
```

Metrics include:

- IoU  
- Dice  
- Precision / Recall  
- Accuracy  
- Boundary IoU  
- Hausdorff Distance  

All results saved as CSV.

---

## ğŸ“Š Tiling Pipeline (Ortho â†’ 512Ã—512 Tiles)

Use the tiling tool to convert orthomosaics into dataset tiles:

```
utils/tiling/tile_pair.py
```

Outputs:

```
tiles/
â”œâ”€â”€ image/
â”œâ”€â”€ mask/ (if available)
â””â”€â”€ manifest.csv
```

Supports:

- custom overlap  
- edge alignment  
- paired image + index extraction  

---

## ğŸ“ TODO

- [ ] Add DDP multi-GPU training  
- [ ] Add mixed-precision training (AMP)  
- [ ] Upload pre-trained regional U-Net models  
- [ ] Add visualization notebook  
- [ ] Publish evaluation benchmark results  

---

## ğŸ“„ License

MIT License.  
Please cite this repository if used in your research.

